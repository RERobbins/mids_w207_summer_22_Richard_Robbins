{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKsRDH5ZUdfasdv"
   },
   "source": [
    "# Lab 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43534tdfgs-v"
   },
   "source": [
    "This lab connects all the pieces involved in training feed-forward fully connected neural networks. You will run a full set of experiments to explore different hyperparameters and hidden layer sizes for both the MNIST and FASHION_MNIST datasets, and report your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7X58hOMTUH-w"
   },
   "outputs": [],
   "source": [
    "# Import the libraries we'll use below.\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style=\"darkgrid\")  # default style\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL5O-SOu7kYN"
   },
   "source": [
    "## Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYpm_zG37xay"
   },
   "source": [
    "### Fashion MNIST\n",
    "\n",
    "We load the fashion_mnist dataset as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 1733,
     "status": "ok",
     "timestamp": 1622667905055,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "load_auto_data_set_code",
    "outputId": "99d54f72-4abc-49f5-cdff-7d3833e3be50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: t-shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# Load the Fashion MNIST dataset.\n",
    "(X_train_fashion, Y_train_fashion), (X_test_fashion, Y_test_fashion) = fashion_mnist.load_data()\n",
    "X_train_fashion = X_train_fashion / 255.\n",
    "X_test_fashion = X_test_fashion / 255.\n",
    "\n",
    "# Flatten Y_train and Y_test, so they become vectors of label values.\n",
    "Y_train_fashion = Y_train_fashion.flatten()\n",
    "Y_test_fashion = Y_test_fashion.flatten()\n",
    "\n",
    "label_names = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "               'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "# Apply random shufflying to training examples.\n",
    "np.random.seed(0)\n",
    "indices = np.arange(X_train_fashion.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "X_train_fashion = X_train_fashion[shuffled_indices]\n",
    "Y_train_fashion = Y_train_fashion[shuffled_indices]\n",
    "\n",
    "# Show the first training example.\n",
    "print('Label: %s' %label_names[Y_train_fashion[0]])\n",
    "plt.imshow(X_train_fashion[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND9b1ShF745M"
   },
   "source": [
    "### MNIST\n",
    "\n",
    "We also load the (digits) mnist dataset in the same way. Note that the number of train/test examples as well as the data shapes are identical to fashion_mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1622667906354,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "ACD38quoz8D_",
    "outputId": "a294a8c6-de0a-421f-c17a-fe9ee1e79767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset.\n",
    "(X_train_digits, Y_train_digits), (X_test_digits, Y_test_digits) = mnist.load_data()\n",
    "X_train_digits = X_train_digits / 255\n",
    "X_test_digits = X_test_digits / 255\n",
    "\n",
    "# Flatten Y_train and Y_test, so they become vectors of label values.\n",
    "Y_train_digits = Y_train_digits.flatten()\n",
    "Y_test_digits = Y_test_digits.flatten()\n",
    "\n",
    "# Apply random shufflying to training examples.\n",
    "np.random.seed(0)\n",
    "indices = np.arange(X_train_digits.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "X_train_digits = X_train_digits[shuffled_indices]\n",
    "Y_train_digits = Y_train_digits[shuffled_indices]\n",
    "\n",
    "# Show the first training example.\n",
    "print('Label: %d' %Y_train_digits[0])\n",
    "plt.imshow(X_train_digits[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09EpBz1w0_Nj"
   },
   "source": [
    "## Build a Model\n",
    "\n",
    "We will write a build_model function that allows for a range of experiments on both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWbRPrMyHZ2J"
   },
   "source": [
    "---\n",
    "### Exercise 1 (58points)\n",
    "\n",
    "Fill in code that implements the build_model function, including all the arguments listed in the function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-GeBGPGhQ5bu"
   },
   "outputs": [],
   "source": [
    "def build_model(n_classes,\n",
    "                hidden_layer_sizes=[],\n",
    "                activation='relu',\n",
    "                optimizer='SGD',\n",
    "                learning_rate=0.01):\n",
    "  \"\"\"Build a multi-class logistic regression model using Keras.\n",
    "\n",
    "  Args:\n",
    "    n_classes: Number of output classes in the dataset.\n",
    "    hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "    activation: The activation function to use for the hidden layers.\n",
    "    optimizer: The optimizer to use (SGD, Adam).\n",
    "    learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "  Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "  \"\"\"\n",
    "\n",
    "  tf.keras.backend.clear_session()\n",
    "  np.random.seed(0)\n",
    "  tf.random.set_seed(0)\n",
    "\n",
    "  model = keras.Sequential()\n",
    "\n",
    "  model.add(keras.layers.Dense(\n",
    "      units=n_classes,\n",
    "      use_bias=True,\n",
    "      activation=activation,\n",
    "      kernel_initializer=tf.ones_initializer\n",
    "  )) \n",
    "\n",
    "  if optimizer == 'SGD':\n",
    "     optimizer = tf.keras.optimizers.SGD (learning_rate=learning_rate)\n",
    "  else:\n",
    "     optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)     \n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO-d_F58Q-6O"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYpd5gUeH9pn"
   },
   "source": [
    "## Run Experiments\n",
    "\n",
    "We can now run a suite of experiments to see how the hyperparameters and layer sizes effect performance. The train_and_evaluate function below can be used to run experiments and retrieve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 22089,
     "status": "ok",
     "timestamp": 1622667987968,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "OKeyZXLJJlA4",
    "outputId": "c3dd339a-443d-4830-ece9-adb2873ed629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [64 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [64 28]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at tmp/ipykernel_71555/1633753174.py:31) ]] [Op:__inference_train_function_2112]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m   test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x\u001b[38;5;241m=\u001b[39mX_test, y\u001b[38;5;241m=\u001b[39mY_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     51\u001b[0m                                  return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m test_accuracy\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m%1.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(data, hidden_layer_sizes, activation, optimizer, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Train the model.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m  \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m  \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m  \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Retrieve the training metrics (after each train epoch) and the final test\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# accuracy.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    947\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[0;32m--> 950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    953\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    954\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3037\u001b[0m   (graph_function,\n\u001b[1;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m     args,\n\u001b[1;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1968\u001b[0m     executing_eagerly)\n\u001b[1;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [64 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [64 28]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at tmp/ipykernel_71555/1633753174.py:31) ]] [Op:__inference_train_function_2112]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(data='digits',\n",
    "                       hidden_layer_sizes=[],\n",
    "                       activation='tanh',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       num_epochs=5):\n",
    "\n",
    "  # Build the model.\n",
    "  model = build_model(n_classes=10,\n",
    "                      hidden_layer_sizes=hidden_layer_sizes,\n",
    "                      activation=activation,\n",
    "                      optimizer=optimizer,\n",
    "                      learning_rate=learning_rate)\n",
    "\n",
    "  # Select the dataset.\n",
    "  if data == 'digits':\n",
    "    X_train = X_train_digits\n",
    "    X_test = X_test_digits\n",
    "    Y_train = Y_train_digits\n",
    "    Y_test = Y_test_digits\n",
    "  elif data == 'fashion':\n",
    "    X_train = X_train_fashion\n",
    "    X_test = X_test_fashion\n",
    "    Y_train = Y_train_fashion\n",
    "    Y_test = Y_test_fashion\n",
    "  else:\n",
    "    raise 'Unsupported dataset: %s' %data\n",
    "\n",
    "  # Train the model.\n",
    "  print('Training...')\n",
    "  history = model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=0)\n",
    "\n",
    "  # Retrieve the training metrics (after each train epoch) and the final test\n",
    "  # accuracy.\n",
    "  train_accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "  plt.plot(train_accuracy, label='train_accuracy')\n",
    "  plt.plot(val_accuracy, label='validation accuracy')\n",
    "  plt.xticks(range(num_epochs))\n",
    "  plt.xlabel('Train epochs')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  test_accuracy = model.evaluate(x=X_test, y=Y_test, verbose=0,\n",
    "                                 return_dict=True)['accuracy']\n",
    "  return test_accuracy\n",
    "\n",
    "print('Test Accuracy: %1.4f' %train_and_evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0Ewe-W8IT-J"
   },
   "source": [
    "---\n",
    "### Exercise 2 (8 points)\n",
    "\n",
    "Run experiments and fill in the test results in the table below. Feel free to extend the table to more experiments as you see fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_ddqOToQ6WW"
   },
   "source": [
    "#### Student Solution\n",
    "\n",
    "DATA | HIDDEN SIZES | ACTIVATION | OPTIMIZER | LEARNING RATE | #PARAMETERS | TEST ACCURACY\n",
    "-|-|-|-|-|-|-\n",
    "digits|[]|tanh|SGD|0.01||\n",
    "digits|[]|relu|SGD|0.01||\n",
    "digits|[]|relu|Adam|0.01||\n",
    "digits|[128]|relu|Adam|0.01||\n",
    "digits|[256,128]|relu|Adam|0.01||\n",
    "-\n",
    "fashion|[]|tanh|SGD|0.01||\n",
    "fashion|[]|relu|SGD|0.01||\n",
    "fashion|[]|relu|Adam|0.01||\n",
    "fashion|[128]|relu|Adam|0.01||\n",
    "fashion|[256,128]|relu|Adam|0.01||\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMlQhpKHdte3dv5Jw16gtIs",
   "collapsed_sections": [],
   "name": "06 Neural Networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
